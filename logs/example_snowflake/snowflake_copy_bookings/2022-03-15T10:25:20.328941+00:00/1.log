[2022-03-28 21:17:50,903] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: example_snowflake.snowflake_copy_bookings scheduled__2022-03-15T10:25:20.328941+00:00 [queued]>
[2022-03-28 21:17:50,917] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: example_snowflake.snowflake_copy_bookings scheduled__2022-03-15T10:25:20.328941+00:00 [queued]>
[2022-03-28 21:17:50,917] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-03-28 21:17:50,917] {taskinstance.py:1244} INFO - Starting attempt 1 of 1
[2022-03-28 21:17:50,917] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-03-28 21:17:50,945] {taskinstance.py:1264} INFO - Executing <Task(SnowflakeOperator): snowflake_copy_bookings> on 2022-03-15 10:25:20.328941+00:00
[2022-03-28 21:17:50,951] {standard_task_runner.py:52} INFO - Started process 70 to run task
[2022-03-28 21:17:50,955] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'example_snowflake', 'snowflake_copy_bookings', 'scheduled__2022-03-15T10:25:20.328941+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/load_snowflake.py', '--cfg-path', '/tmp/tmps9flc647', '--error-file', '/tmp/tmp4zaesp01']
[2022-03-28 21:17:50,956] {standard_task_runner.py:77} INFO - Job 68: Subtask snowflake_copy_bookings
[2022-03-28 21:17:51,029] {logging_mixin.py:109} INFO - Running <TaskInstance: example_snowflake.snowflake_copy_bookings scheduled__2022-03-15T10:25:20.328941+00:00 [running]> on host 713dce2392ed
[2022-03-28 21:17:51,133] {taskinstance.py:1431} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=example_snowflake
AIRFLOW_CTX_TASK_ID=snowflake_copy_bookings
AIRFLOW_CTX_EXECUTION_DATE=2022-03-15T10:25:20.328941+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-15T10:25:20.328941+00:00
[2022-03-28 21:17:51,134] {snowflake.py:127} INFO - Executing: copy into PUBLIC.BOOKINGS_1 from s3://gw-test-open-snowflake/***/ FILES=('bookings_1.csv') FILE_FORMAT=(TYPE='CSV' SKIP_HEADER=1);copy into PUBLIC.BOOKINGS_2 from s3://gw-test-open-snowflake/***/ FILES=('bookings_2.csv') FILE_FORMAT=(TYPE='CSV' SKIP_HEADER=1);
[2022-03-28 21:17:51,144] {base.py:79} INFO - Using connection to: id: snowflake_conn. Host: ms36734.ap-southeast-2.snowflakecomputing.com, Port: None, Schema: public, Login: ggww128, Password: ***, extra: {'extra__snowflake__account': 'ms36734', 'extra__snowflake__database': 'DEMO_DBT', 'extra__snowflake__insecure_mode': False, 'extra__snowflake__region': 'ap-southeast-2', 'extra__snowflake__role': 'dbt_DEV_ROLE', 'extra__snowflake__warehouse': 'dbt_DEV_WH'}
[2022-03-28 21:17:51,145] {connection.py:262} INFO - Snowflake Connector for Python Version: 2.4.6, Python Version: 3.7.12, Platform: Linux-5.13.0-25-generic-x86_64-with-debian-10.11
[2022-03-28 21:17:51,146] {connection.py:869} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2022-03-28 21:17:51,146] {connection.py:886} INFO - Setting use_openssl_only mode to False
[2022-03-28 21:17:52,057] {cursor.py:637} INFO - query: [ALTER SESSION SET autocommit=True]
[2022-03-28 21:17:52,225] {cursor.py:661} INFO - query execution done
[2022-03-28 21:17:52,226] {snowflake.py:283} INFO - Running statement: copy into PUBLIC.BOOKINGS_1 from s3://gw-test-open-snowflake/***/ FILES=('bookings_1.csv') FILE_FORMAT=(TYPE='CSV' SKIP_HEADER=1);, parameters: None
[2022-03-28 21:17:52,226] {cursor.py:637} INFO - query: [copy into PUBLIC.BOOKINGS_1 from s3://gw-test-open-snowflake/***/ FILES=('bo...]
[2022-03-28 21:17:54,743] {cursor.py:661} INFO - query execution done
[2022-03-28 21:17:54,743] {snowflake.py:291} INFO - Statement execution info - {'file': 's3://gw-test-open-snowflake/***/bookings_1.csv', 'status': 'LOAD_SKIPPED', 'rows_parsed': 0, 'rows_loaded': 0, 'error_limit': None, 'errors_seen': 1, 'first_error': 'File was loaded before.', 'first_error_line': None, 'first_error_character': None, 'first_error_column_name': None}
[2022-03-28 21:17:54,743] {json_result.py:127} INFO - fetching data done
[2022-03-28 21:17:54,743] {snowflake.py:294} INFO - Rows affected: 1
[2022-03-28 21:17:54,744] {snowflake.py:295} INFO - Snowflake query id: 01a33c5d-3200-d1de-0000-0000aa29d005
[2022-03-28 21:17:54,744] {snowflake.py:283} INFO - Running statement: copy into PUBLIC.BOOKINGS_2 from s3://gw-test-open-snowflake/***/ FILES=('bookings_2.csv') FILE_FORMAT=(TYPE='CSV' SKIP_HEADER=1);, parameters: None
[2022-03-28 21:17:54,744] {cursor.py:637} INFO - query: [copy into PUBLIC.BOOKINGS_2 from s3://gw-test-open-snowflake/***/ FILES=('bo...]
[2022-03-28 21:17:55,438] {cursor.py:661} INFO - query execution done
[2022-03-28 21:17:55,438] {snowflake.py:291} INFO - Statement execution info - {'file': 's3://gw-test-open-snowflake/***/bookings_2.csv', 'status': 'LOAD_SKIPPED', 'rows_parsed': 0, 'rows_loaded': 0, 'error_limit': None, 'errors_seen': 1, 'first_error': 'File was loaded before.', 'first_error_line': None, 'first_error_character': None, 'first_error_column_name': None}
[2022-03-28 21:17:55,438] {json_result.py:127} INFO - fetching data done
[2022-03-28 21:17:55,438] {snowflake.py:294} INFO - Rows affected: 1
[2022-03-28 21:17:55,438] {snowflake.py:295} INFO - Snowflake query id: 01a33c5d-3200-d1b4-0000-0000aa29c011
[2022-03-28 21:17:55,438] {connection.py:499} INFO - closed
[2022-03-28 21:17:55,460] {connection.py:502} INFO - No async queries seem to be running, deleting session
[2022-03-28 21:17:55,572] {taskinstance.py:1282} INFO - Marking task as SUCCESS. dag_id=example_snowflake, task_id=snowflake_copy_bookings, execution_date=20220315T102520, start_date=20220328T211750, end_date=20220328T211755
[2022-03-28 21:17:55,607] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-28 21:17:55,647] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
